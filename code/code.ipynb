{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Grad School/PhD/AI/Final/Data/SumerSports')\n",
    "import prep_data\n",
    "import process_datasets\n",
    "import models\n",
    "\n",
    "#make sure to pip install polar and pytorch_lightning and pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   count\n",
      "receiverAlignment       \n",
      "1x0                    8\n",
      "1x1                  160\n",
      "2x0                   45\n",
      "2x1                 1824\n",
      "2x2                 6483\n",
      "3x0                    9\n",
      "3x1                 6044\n",
      "3x2                 1232\n",
      "3x3                    1\n",
      "4x1                  129\n",
      "4x2                    1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plays_df = pd.read_csv('D:/Grad School/PhD/AI/Final/Data/input_data/plays.csv')\n",
    "\n",
    "receiverA_counts =(plays_df['receiverAlignment']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .to_frame()\n",
    ")\n",
    "\n",
    "print(receiverA_counts)\n",
    "output_dimenstion = plays_df['receiverAlignment'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load players\n",
      "Load plays\n",
      "Load tracking\n",
      "tracking_df rows: 6795800\n",
      "Add features to tracking\n",
      "Convert tracking to cartesian\n",
      "Standardize play direction\n",
      "Augment data by mirroring\n",
      "Generate target - receiverAlignment\n",
      "Split train/test/val\n",
      "Total set: 3848 plays, 614734 frames\n",
      "Train set: 2694 plays, 424714 frames\n",
      "Test set: 576 plays, 94456 frames\n",
      "Validation set: 578 plays, 95564 frames\n"
     ]
    }
   ],
   "source": [
    "prep_data.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset for model_type='transformer', split='test'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-computing feature transforms: 100%|██████████| 94456/94456 [00:55<00:00, 1701.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.6 mins\n",
      "Creating dataset for model_type='transformer', split='val'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-computing feature transforms: 100%|██████████| 95564/95564 [00:55<00:00, 1716.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 3.1 mins\n",
      "Creating dataset for model_type='transformer', split='train'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-computing feature transforms: 100%|██████████| 424714/424714 [04:10<00:00, 1697.25it/s]\n"
     ]
    }
   ],
   "source": [
    "process_datasets.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from process_datasets import load_datasets\n",
    "\n",
    "train_dataset = load_datasets(model_type = 'transformer', split = 'train')\n",
    "val_dataset = load_datasets(model_type = 'transformer', split = 'val')\n",
    "test_dataset = load_datasets(model_type = 'transformer', split = 'test')\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 3)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, num_workers = 3)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 3)\n",
    "\n",
    "for batch in train_loader:\n",
    "    features, targets = batch\n",
    "    print(\"Train features shape:\", features.shape)\n",
    "    print(\"Train targets shape:\", targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SportsTransformerLitModel\n",
    "\n",
    "feature_len = 5\n",
    "model_dim = 64 #adjustable\n",
    "num_layers = 4 #adjustable\n",
    "dropout = 0.01\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "output_dim = plays_df['receiverAlignment'].nunique()\n",
    "\n",
    "model = SportsTransformerLitModel(\n",
    "    feature_len = feature_len,\n",
    "    model_dim = model_dim,\n",
    "    num_layers = num_layers,\n",
    "    output_dim = output_dim,\n",
    "    dropout = dropout,\n",
    "    learning_rate = learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lighting import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = Path(\"checkpoints/\"),\n",
    "    filename = \"best-checkpoint\",\n",
    "    save_top_k = 1,\n",
    "    verbose = True,\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\",\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    min_delta = 0.01,\n",
    "    patience - 3,\n",
    "    verbose = True,\n",
    "    mode = \"min\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs = 20,\n",
    "    accelerator = \"gpu\",\n",
    "    devices = 1,\n",
    "    callbacks = checkpoint_callback, early_stop_callback\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
